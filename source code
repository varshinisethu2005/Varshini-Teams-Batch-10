# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Load MNIST dataset from Keras
from tensorflow.keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Convert to DataFrame using Pandas (for EDA and preprocessing)
df_train = pd.DataFrame(X_train.reshape(X_train.shape[0], -1))
df_train['label'] = y_train

df_test = pd.DataFrame(X_test.reshape(X_test.shape[0], -1))
df_test['label'] = y_test

# EDA: Histogram of class distribution
sns.countplot(x='label', data=df_train)
plt.title("Digit Class Distribution (Train Set)")
plt.show()

# Normalize pixel values (0-255 â†’ 0-1)
X_train = X_train / 255.0
X_test = X_test / 255.0

# One-hot encode labels
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

# Build a simple Neural Network
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

# Compile model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
model.fit(X_train, y_train_cat, epochs=5, validation_data=(X_test, y_test_cat))

# Evaluate model
test_loss, test_acc = model.evaluate(X_test, y_test_cat)
print(f"Test Accuracy: {test_acc:.4f}")

# Predictions and Evaluation
y_pred = model.predict(X_test)
y_pred_labels = np.argmax(y_pred, axis=1)

# Confusion matrix and classification report
print(confusion_matrix(y_test, y_pred_labels))
print(classification_report(y_test, y_pred_labels))
